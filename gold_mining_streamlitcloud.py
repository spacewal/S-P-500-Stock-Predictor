# -*- coding: utf-8 -*-
"""gold_mining_streamLitCloud.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NTkM7Dfro7pX-kTdz5qOp9KPzcyW8GGF
"""

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, BatchNormalization
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger
from datetime import datetime
import matplotlib.pyplot as plt

# Function to fetch S&P 500 companies and sectors
@st.cache_resource
def get_sp500_companies():
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
    df = pd.read_html(url, header=0)[0]
    return df[['Symbol', 'GICS Sector']]

# Function to fetch S&P 500 tickers list
@st.cache_resource
def get_sp500_tickers():
    df = get_sp500_companies()
    return df['Symbol'].tolist()

# Function to fetch stock data
@st.cache_resource
def fetch_data(ticker, start_date, end_date):
    data = yf.download(ticker, start=start_date, end=end_date)
    data.dropna(inplace=True)
    return data

# Function to preprocess data and train LSTM model
@st.cache_resource
def train_model(X_train, y_train):
    model = Sequential([
        LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
        LSTM(units=50, return_sequences=False),
        Dense(1)
    ])
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=5),
        ModelCheckpoint('best_model.keras', save_best_only=True),
        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),
        TensorBoard(log_dir='./logs'),
        CSVLogger('training_log.csv')
    ]
    
    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=callbacks)
    return model

# Function to analyze and predict stock price
def analyze_stock(ticker):
    data = fetch_data(ticker, '2020-01-01', datetime.today().strftime('%Y-%m-%d'))
    scaler = MinMaxScaler(feature_range=(0, 1))
    data_scaled = scaler.fit_transform(data['Close'].values.reshape(-1, 1))

    X, y = [], []
    for i in range(60, len(data_scaled)):
        X.append(data_scaled[i-60:i, 0])
        y.append(data_scaled[i, 0])

    X_train, y_train = np.array(X[:int(len(X) * 0.8)]), np.array(y[:int(len(y) * 0.8)])
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

    model = train_model(X_train, y_train)

    # Predicting the closing prices using the trained model
    latest_scaled = scaler.transform(data['Close'].values[-60:].reshape(-1, 1))
    latest_scaled = np.reshape(latest_scaled, (1, latest_scaled.shape[0], 1))
    predicted = model.predict(latest_scaled)
    predicted_prices = scaler.inverse_transform(predicted)

    # Plot the results
    plt.figure(figsize=(10, 5))
    plt.plot(data['Close'].tail(60).index, data['Close'].tail(60).values, color='blue', label='Actual Prices')
    predicted_dates = pd.date_range(start=data.tail(1).index[0], periods=len(predicted), freq='B')
    plt.plot(predicted_dates, predicted_prices, color='red', label='Predicted Prices')
    plt.title(f'{ticker} Stock Price Prediction')
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.legend()
    plt.grid(True)
    st.pyplot(plt)

# Main function to run the Streamlit app
def main():
    st.title("S&P 500 Stock Predictor")
    sp500_companies = get_sp500_companies()
    tickers = get_sp500_tickers()

    selected_ticker = st.selectbox("Choose a ticker to analyze", [''] + tickers)
    if selected_ticker:
        analyze_stock(selected_ticker)

    st.write("S&P 500 Dashboard")
    st.table(sp500_companies)  # Display the S&P 500 dashboard

if __name__ == "__main__":
    main()
